{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14ec3f4-7cb8-4371-9f02-75914f8a4505",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c695ab14-821f-4c52-bd6f-9451cbb0b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "(363, 4)\n",
      "Index(['Plant Name', 'Disease Name', 'Symptoms', 'Treatments'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plant Name</th>\n",
       "      <th>Disease Name</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Treatments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Early Blight</td>\n",
       "      <td>Brown concentric spots (target spots) on older...</td>\n",
       "      <td>Apply Mancozeb or Chlorothalonil; remove infec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Late Blight</td>\n",
       "      <td>Dark patches on leaves and fruits; foul odor; ...</td>\n",
       "      <td>Spray Metalaxyl or Copper oxychloride; improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Leaf Curl Virus</td>\n",
       "      <td>Upward curling leaves; stunted plant; reduced ...</td>\n",
       "      <td>Control whiteflies (vector) with insecticides;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Bacterial Canker</td>\n",
       "      <td>White-margined spots (bird's-eye) on fruit; ma...</td>\n",
       "      <td>Use clean seeds; apply Copper spray; avoid spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Target Spot</td>\n",
       "      <td>Small, dark brown to black spots with light ce...</td>\n",
       "      <td>Apply Chlorothalonil or Mancozeb; ensure good ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Plant Name      Disease Name  \\\n",
       "0     Tomato      Early Blight   \n",
       "1     Tomato       Late Blight   \n",
       "2     Tomato   Leaf Curl Virus   \n",
       "3     Tomato  Bacterial Canker   \n",
       "4     Tomato       Target Spot   \n",
       "\n",
       "                                            Symptoms  \\\n",
       "0  Brown concentric spots (target spots) on older...   \n",
       "1  Dark patches on leaves and fruits; foul odor; ...   \n",
       "2  Upward curling leaves; stunted plant; reduced ...   \n",
       "3  White-margined spots (bird's-eye) on fruit; ma...   \n",
       "4  Small, dark brown to black spots with light ce...   \n",
       "\n",
       "                                          Treatments  \n",
       "0  Apply Mancozeb or Chlorothalonil; remove infec...  \n",
       "1  Spray Metalaxyl or Copper oxychloride; improve...  \n",
       "2  Control whiteflies (vector) with insecticides;...  \n",
       "3  Use clean seeds; apply Copper spray; avoid spl...  \n",
       "4  Apply Chlorothalonil or Mancozeb; ensure good ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your raw dataset\n",
    "df = pd.read_excel(\"..\\data\\TextDataSet.xlsx\")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9e7cd2-8946-4f50-9765-2e3367b3ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error Tunnel connection\n",
      "[nltk_data]     failed: 407 Proxy Authentication Required>\n",
      "[nltk_data] Error loading stopwords: <urlopen error Tunnel connection\n",
      "[nltk_data]     failed: 407 Proxy Authentication Required>\n",
      "[nltk_data] Error loading wordnet: <urlopen error Tunnel connection\n",
      "[nltk_data]     failed: 407 Proxy Authentication Required>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All text columns cleaned successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plant Name</th>\n",
       "      <th>Disease Name</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Treatments</th>\n",
       "      <th>Cleaned_Plant_Name</th>\n",
       "      <th>Cleaned_Disease_Name</th>\n",
       "      <th>Cleaned_Symptoms</th>\n",
       "      <th>Cleaned_Treatments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Early Blight</td>\n",
       "      <td>Brown concentric spots (target spots) on older...</td>\n",
       "      <td>Apply Mancozeb or Chlorothalonil; remove infec...</td>\n",
       "      <td>tomato</td>\n",
       "      <td>early blight</td>\n",
       "      <td>brown concentric spot target spot older leaf y...</td>\n",
       "      <td>apply mancozeb chlorothalonil remove infected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Late Blight</td>\n",
       "      <td>Dark patches on leaves and fruits; foul odor; ...</td>\n",
       "      <td>Spray Metalaxyl or Copper oxychloride; improve...</td>\n",
       "      <td>tomato</td>\n",
       "      <td>late blight</td>\n",
       "      <td>dark patch leaf fruit foul odor rapid blighting</td>\n",
       "      <td>spray metalaxyl copper oxychloride improve air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Leaf Curl Virus</td>\n",
       "      <td>Upward curling leaves; stunted plant; reduced ...</td>\n",
       "      <td>Control whiteflies (vector) with insecticides;...</td>\n",
       "      <td>tomato</td>\n",
       "      <td>leaf curl virus</td>\n",
       "      <td>upward curling leaf stunted plant reduced frui...</td>\n",
       "      <td>control whitefly vector insecticide use resist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Bacterial Canker</td>\n",
       "      <td>White-margined spots (bird's-eye) on fruit; ma...</td>\n",
       "      <td>Use clean seeds; apply Copper spray; avoid spl...</td>\n",
       "      <td>tomato</td>\n",
       "      <td>bacterial canker</td>\n",
       "      <td>whitemargined spot birdseye fruit marginal lea...</td>\n",
       "      <td>use clean seed apply copper spray avoid splash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tomato</td>\n",
       "      <td>Target Spot</td>\n",
       "      <td>Small, dark brown to black spots with light ce...</td>\n",
       "      <td>Apply Chlorothalonil or Mancozeb; ensure good ...</td>\n",
       "      <td>tomato</td>\n",
       "      <td>target spot</td>\n",
       "      <td>small dark brown black spot light center leaf ...</td>\n",
       "      <td>apply chlorothalonil mancozeb ensure good air ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Plant Name      Disease Name  \\\n",
       "0     Tomato      Early Blight   \n",
       "1     Tomato       Late Blight   \n",
       "2     Tomato   Leaf Curl Virus   \n",
       "3     Tomato  Bacterial Canker   \n",
       "4     Tomato       Target Spot   \n",
       "\n",
       "                                            Symptoms  \\\n",
       "0  Brown concentric spots (target spots) on older...   \n",
       "1  Dark patches on leaves and fruits; foul odor; ...   \n",
       "2  Upward curling leaves; stunted plant; reduced ...   \n",
       "3  White-margined spots (bird's-eye) on fruit; ma...   \n",
       "4  Small, dark brown to black spots with light ce...   \n",
       "\n",
       "                                          Treatments Cleaned_Plant_Name  \\\n",
       "0  Apply Mancozeb or Chlorothalonil; remove infec...             tomato   \n",
       "1  Spray Metalaxyl or Copper oxychloride; improve...             tomato   \n",
       "2  Control whiteflies (vector) with insecticides;...             tomato   \n",
       "3  Use clean seeds; apply Copper spray; avoid spl...             tomato   \n",
       "4  Apply Chlorothalonil or Mancozeb; ensure good ...             tomato   \n",
       "\n",
       "  Cleaned_Disease_Name                                   Cleaned_Symptoms  \\\n",
       "0         early blight  brown concentric spot target spot older leaf y...   \n",
       "1          late blight    dark patch leaf fruit foul odor rapid blighting   \n",
       "2      leaf curl virus  upward curling leaf stunted plant reduced frui...   \n",
       "3     bacterial canker  whitemargined spot birdseye fruit marginal lea...   \n",
       "4          target spot  small dark brown black spot light center leaf ...   \n",
       "\n",
       "                                  Cleaned_Treatments  \n",
       "0  apply mancozeb chlorothalonil remove infected ...  \n",
       "1  spray metalaxyl copper oxychloride improve air...  \n",
       "2  control whitefly vector insecticide use resist...  \n",
       "3  use clean seed apply copper spray avoid splash...  \n",
       "4  apply chlorothalonil mancozeb ensure good air ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans, tokenizes, removes stopwords, and lemmatizes text.\"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    words = nltk.word_tokenize(text)  # tokenize\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]  # remove stopwords & lemmatize\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply to all text columns\n",
    "for col in [\"Plant Name\", \"Disease Name\", \"Symptoms\", \"Treatments\"]:\n",
    "    new_col = \"Cleaned_\" + col.replace(\" \", \"_\")\n",
    "    df[new_col] = df[col].apply(preprocess_text)\n",
    "\n",
    "print(\"âœ… All text columns cleaned successfully!\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ecf5a-3531-4056-beae-619e79427f5c",
   "metadata": {},
   "source": [
    "# Balance the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17669c16-6b39-4efa-b470-62b2c69b404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Before balancing: 363 samples, 243 unique diseases\n",
      "âœ… Balancing complete!\n",
      "ðŸ“ˆ After balancing: 3645 samples\n",
      "ðŸ§© Each disease count:\n",
      "Cleaned_Disease_Name\n",
      "black knot dibotryon             15\n",
      "powdery mildew                   15\n",
      "fruit shoot borer                15\n",
      "gray leaf spot pestalotiopsis    15\n",
      "leaf spot                        15\n",
      "white rust                       15\n",
      "root rot aphanomyces             15\n",
      "fruit spot cercospora            15\n",
      "rhizosphaera needle cast         15\n",
      "fruit canker                     15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Create a balanced dataset based on 'Cleaned_Disease_Name'\n",
    "balanced_df = pd.DataFrame()\n",
    "\n",
    "# Find minimum and maximum class counts\n",
    "class_counts = df['Cleaned_Disease_Name'].value_counts()\n",
    "min_class = class_counts.min()\n",
    "max_class = class_counts.max()\n",
    "\n",
    "print(f\"ðŸ“Š Before balancing: {len(df)} samples, {len(class_counts)} unique diseases\")\n",
    "\n",
    "# Oversample rare classes up to a fixed limit\n",
    "target_size = min(max_class, 30)  # cap at 30 per disease to avoid overfitting\n",
    "\n",
    "for disease, subset in df.groupby('Cleaned_Disease_Name'):\n",
    "    if len(subset) < target_size:\n",
    "        subset_resampled = resample(subset, \n",
    "                                    replace=True, \n",
    "                                    n_samples=target_size, \n",
    "                                    random_state=42)\n",
    "    else:\n",
    "        subset_resampled = subset.sample(target_size, random_state=42)\n",
    "    balanced_df = pd.concat([balanced_df, subset_resampled])\n",
    "\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)  # shuffle\n",
    "\n",
    "print(\"âœ… Balancing complete!\")\n",
    "print(\"ðŸ“ˆ After balancing:\", len(balanced_df), \"samples\")\n",
    "print(\"ðŸ§© Each disease count:\")\n",
    "print(balanced_df['Cleaned_Disease_Name'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7282a4f-2ec7-488c-bce3-e8b0c0db9ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paraphrased symptom sentences created successfully!\n",
      "                                    Cleaned_Symptoms  \\\n",
      "0         hard black warty swelling knot twig branch   \n",
      "1           small circular dark spot fruit leaf twig   \n",
      "2                     reddishpurple spot flower leaf   \n",
      "3  sudden irreversible wilting without leaf yello...   \n",
      "4                         curled leaf mosaic pattern   \n",
      "5             concentric dark spot light center leaf   \n",
      "6               dark irregular lesion leaflet margin   \n",
      "7            salmonpink fungal spore dying leaf stem   \n",
      "8               yellow spot needle turn reddishbrown   \n",
      "9    yellow brown spot leaf turning rusty underneath   \n",
      "\n",
      "                                   Expanded_Symptoms  \n",
      "0  Typical symptom: hard black warty swelling kno...  \n",
      "1  The plant exhibits small circular dark spot fr...  \n",
      "2  This disease shows reddishpurple spot flower l...  \n",
      "3  This disease shows sudden irreversible wilting...  \n",
      "4  This disease shows curled leaf mosaic pattern ...  \n",
      "5  Typical symptom: concentric dark spot light ce...  \n",
      "6  Leaves show dark irregular lesion leaflet margin.  \n",
      "7  The plant exhibits salmonpink fungal spore dyi...  \n",
      "8  Leaves show yellow spot needle turn reddishbrown.  \n",
      "9  Typical symptom: yellow brown spot leaf turnin...  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Function to generate natural symptom sentences\n",
    "def paraphrase(text):\n",
    "    templates = [\n",
    "        f\"Symptoms observed: {text}\",\n",
    "        f\"The plant exhibits {text}.\",\n",
    "        f\"Common signs include {text}.\",\n",
    "        f\"Leaves show {text}.\",\n",
    "        f\"Typical symptom: {text}.\",\n",
    "        f\"This disease shows {text} on affected parts.\"\n",
    "    ]\n",
    "    return random.choice(templates)\n",
    "\n",
    "# Apply paraphrasing to the cleaned symptom column\n",
    "balanced_df[\"Expanded_Symptoms\"] = balanced_df[\"Cleaned_Symptoms\"].apply(paraphrase)\n",
    "\n",
    "print(\"âœ… Paraphrased symptom sentences created successfully!\")\n",
    "print(balanced_df[[\"Cleaned_Symptoms\", \"Expanded_Symptoms\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891dc283-8f2a-4263-b321-6579709c2177",
   "metadata": {},
   "source": [
    "# Final Clean-Up of Expanded Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1fcf71c-1b47-4486-8f15-5f5dea6901d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final cleanup done on expanded symptoms!\n",
      "                                   Expanded_Symptoms  \\\n",
      "0  Typical symptom: hard black warty swelling kno...   \n",
      "1  The plant exhibits small circular dark spot fr...   \n",
      "2  This disease shows reddishpurple spot flower l...   \n",
      "3  This disease shows sudden irreversible wilting...   \n",
      "4  This disease shows curled leaf mosaic pattern ...   \n",
      "5  Typical symptom: concentric dark spot light ce...   \n",
      "6  Leaves show dark irregular lesion leaflet margin.   \n",
      "7  The plant exhibits salmonpink fungal spore dyi...   \n",
      "8  Leaves show yellow spot needle turn reddishbrown.   \n",
      "9  Typical symptom: yellow brown spot leaf turnin...   \n",
      "\n",
      "                                      Final_Symptoms  \n",
      "0  typical symptom hard black warty swelling knot...  \n",
      "1  the plant exhibits small circular dark spot fr...  \n",
      "2  this disease shows reddishpurple spot flower l...  \n",
      "3  this disease shows sudden irreversible wilting...  \n",
      "4  this disease shows curled leaf mosaic pattern ...  \n",
      "5  typical symptom concentric dark spot light cen...  \n",
      "6   leaves show dark irregular lesion leaflet margin  \n",
      "7  the plant exhibits salmonpink fungal spore dyi...  \n",
      "8   leaves show yellow spot needle turn reddishbrown  \n",
      "9  typical symptom yellow brown spot leaf turning...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def final_clean(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # convert to lowercase\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove punctuation/symbols\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
    "    return text\n",
    "\n",
    "balanced_df[\"Final_Symptoms\"] = balanced_df[\"Expanded_Symptoms\"].apply(final_clean)\n",
    "\n",
    "print(\"âœ… Final cleanup done on expanded symptoms!\")\n",
    "print(balanced_df[[\"Expanded_Symptoms\", \"Final_Symptoms\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eca028d1-20ee-4abb-a8aa-986c9170c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final dataset saved successfully!\n",
      "ðŸ“ Saved as: Final_Cleaned_Balanced_Dataset.xlsx in your PlantDocBot folder\n",
      "ðŸ“Š Shape: (3645, 10)\n",
      "ðŸ§© Columns: ['Plant Name', 'Disease Name', 'Symptoms', 'Treatments', 'Cleaned_Plant_Name', 'Cleaned_Disease_Name', 'Cleaned_Symptoms', 'Cleaned_Treatments', 'Expanded_Symptoms', 'Final_Symptoms']\n"
     ]
    }
   ],
   "source": [
    "# Save the fully cleaned, balanced, and finalized dataset\n",
    "balanced_df.to_excel(\"..\\data\\processed\\Final_Cleaned_Balanced_Dataset.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… Final dataset saved successfully!\")\n",
    "print(\"ðŸ“ Saved as: Final_Cleaned_Balanced_Dataset.xlsx in your PlantDocBot folder\")\n",
    "print(\"ðŸ“Š Shape:\", balanced_df.shape)\n",
    "print(\"ðŸ§© Columns:\", list(balanced_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b47778f-80c9-4304-be15-a0724fb14879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "  Plant Name            Disease Name  \\\n",
      "0       Plum  Black Knot (Dibotryon)   \n",
      "1      Peach     Scab (Cladosporium)   \n",
      "2    Dogwood        Spot Anthracnose   \n",
      "3      Chili          Bacterial Wilt   \n",
      "4     Papaya         Leaf Curl Virus   \n",
      "\n",
      "                                            Symptoms  \\\n",
      "0  Hard, black, warty swellings (knots) on twigs ...   \n",
      "1  Small, circular, dark spots on fruit, leaves, ...   \n",
      "2         Reddish-purple spots on flowers and leaves   \n",
      "3  Sudden, irreversible wilting without leaf yell...   \n",
      "4                     Curled leaves; mosaic patterns   \n",
      "\n",
      "                                          Treatments Cleaned_Plant_Name  \\\n",
      "0  Prune out knots in winter; apply Chlorothaloni...               plum   \n",
      "1       Apply Captan or Chlorothalonil at petal fall              peach   \n",
      "2                  Apply Chlorothalonil at bud break            dogwood   \n",
      "3  Plant resistant varieties; avoid planting in i...              chili   \n",
      "4      Control whiteflies; plant resistant varieties             papaya   \n",
      "\n",
      "   Cleaned_Disease_Name                                   Cleaned_Symptoms  \\\n",
      "0  black knot dibotryon         hard black warty swelling knot twig branch   \n",
      "1     scab cladosporium           small circular dark spot fruit leaf twig   \n",
      "2      spot anthracnose                     reddishpurple spot flower leaf   \n",
      "3        bacterial wilt  sudden irreversible wilting without leaf yello...   \n",
      "4       leaf curl virus                         curled leaf mosaic pattern   \n",
      "\n",
      "                                  Cleaned_Treatments  \\\n",
      "0   prune knot winter apply chlorothalonil bud break   \n",
      "1             apply captan chlorothalonil petal fall   \n",
      "2                     apply chlorothalonil bud break   \n",
      "3  plant resistant variety avoid planting infeste...   \n",
      "4           control whitefly plant resistant variety   \n",
      "\n",
      "                                   Expanded_Symptoms  \\\n",
      "0  Typical symptom: hard black warty swelling kno...   \n",
      "1  The plant exhibits small circular dark spot fr...   \n",
      "2  This disease shows reddishpurple spot flower l...   \n",
      "3  This disease shows sudden irreversible wilting...   \n",
      "4  This disease shows curled leaf mosaic pattern ...   \n",
      "\n",
      "                                      Final_Symptoms  \n",
      "0  typical symptom hard black warty swelling knot...  \n",
      "1  the plant exhibits small circular dark spot fr...  \n",
      "2  this disease shows reddishpurple spot flower l...  \n",
      "3  this disease shows sudden irreversible wilting...  \n",
      "4  this disease shows curled leaf mosaic pattern ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your last cleaned and expanded dataset\n",
    "df = pd.read_excel(\"..\\data\\processed\\Final_Cleaned_Balanced_Dataset.xlsx\")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6e53f-9901-4665-8c7c-e0539f3484e2",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f1d5fc-9169-4d50-b884-5e6bbcfce1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Labels encoded!\n",
      "Unique labels: 243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"Cleaned_Disease_Name\"])\n",
    "\n",
    "print(\"âœ… Labels encoded!\")\n",
    "print(\"Unique labels:\", len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf12156-c9b6-4d93-9346-f9bccdfc8695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aerial blight phytophthora' 'algal leaf spot green scurf'\n",
      " 'alternaria leaf blight' 'alternaria leaf spot'\n",
      " 'angular leaf spot bacterial' 'anthracnose' 'anthracnose colletotrichum'\n",
      " 'apple scab' 'ascochyta blight' 'bacterial blast pseudomonas'\n",
      " 'bacterial blight' 'bacterial blight angular leaf spot'\n",
      " 'bacterial blight xanthomonas' 'bacterial canker' 'bacterial leaf blight'\n",
      " 'bacterial leaf spot' 'bacterial ring rot' 'bacterial soft rot'\n",
      " 'bacterial spot' 'bacterial wilt' 'basal rot' 'basal rot fusarium'\n",
      " 'bayoud disease fusarium wilt' 'beech bark disease' 'berry disease'\n",
      " 'bitter rot' 'black canker' 'black knot dibotryon'\n",
      " 'black pod phytophthora' 'black rot' 'black rot bacterial'\n",
      " 'black rot phytophthora' 'black scurf' 'black spot'\n",
      " 'black spot alternaria' 'black spot diplocarpon' 'blackleg'\n",
      " 'blast disease' 'blister blight' 'boll rot'\n",
      " 'botryosphaeria panicle shoot blight' 'botrytis blight'\n",
      " 'botrytis blight gray mold' 'bottom rot' 'boxwood blight'\n",
      " 'bronze birch borer' 'brown blight colletotrichum' 'brown rot'\n",
      " 'brown spot' 'bud blast pycnostysanus' 'bud rot' 'bud rot phytophthora'\n",
      " 'bunchy top virus' 'cane blight botrytis' 'cane canker' 'canker'\n",
      " 'canker dieback' 'cavity spot pythium' 'cedar apple rust'\n",
      " 'cedar rust gall' 'cercospora leaf spot' 'charcoal rot macrophomina'\n",
      " 'citrus canker' 'citrus tristeza virus' 'clubroot' 'collar rot'\n",
      " 'common blight bacterial' 'common rust' 'coryneum blight shot hole'\n",
      " 'crown gall agrobacterium' 'crown rot phytophthora' 'crown rust'\n",
      " 'dieback' 'dieback colletotrichum' 'dieback pink disease'\n",
      " 'diplodia tip blight' 'downy blight' 'downy mildew'\n",
      " 'dutch elm disease fungus' 'early blight' 'early leaf spot cercospora'\n",
      " 'eastern filbert blight' 'false smut' 'fig mosaic virus' 'fire blight'\n",
      " 'fire botrytis blight' 'flower blight' 'foot rot phytophthora'\n",
      " 'freckle black spot' 'fruit blotch acidovorax' 'fruit canker'\n",
      " 'fruit rot phytophthora' 'fruit shoot borer' 'fruit spot alternaria'\n",
      " 'fruit spot cercospora' 'fruit spot colletotrichum'\n",
      " 'fusarium head blight scab' 'fusarium wilt' 'fusarium wilt race 4'\n",
      " 'ganoderma butt rot' 'grain smut' 'grassy shoot disease phytoplasma'\n",
      " 'gray leaf spot' 'gray leaf spot pestalotiopsis' 'gray mold'\n",
      " 'gray mold botrytis' 'greasy spot mycosphaerella' 'greening disease'\n",
      " 'gummosis bacterial' 'gummy stem blight' 'halo blight bacterial'\n",
      " 'head smut' 'healthy' 'hemlock woolly adelgid' 'hypoxylon root rot'\n",
      " 'iris yellow spot virus' 'lace bug damage' 'late blight'\n",
      " 'late blight septoria' 'leaf blight' 'leaf blight phytophthora'\n",
      " 'leaf blister taphrina' 'leaf blotch' 'leaf curl' 'leaf curl virus'\n",
      " 'leaf gall' 'leaf mold' 'leaf rot' 'leaf rust' 'leaf scorch' 'leaf spot'\n",
      " 'leaf spot alternaria' 'leaf spot cercospora'\n",
      " 'leaf spot cherry leaf spot' 'leaf spot colletotrichum'\n",
      " 'leaf spot common leaf spot' 'leaf spot coniothyrium'\n",
      " 'leaf spot didymellina' 'leaf spot mycosphaerella' 'leaf spot septoria'\n",
      " 'leaf spot xanthomonas' 'leather rot phytophthora' 'little leaf'\n",
      " 'loose smut' 'malformation fungal' 'melanose diaporthe' 'mint rust'\n",
      " 'mosaic virus' 'mummy berry' 'neck rot botrytis'\n",
      " 'needle blight dothistroma' 'needle cast' 'net blotch'\n",
      " 'northern leaf blight' 'orange rust' 'panama wilt'\n",
      " 'peacock spot cycloconium' 'pear scab' 'petal blight' 'phomopsis blight'\n",
      " 'phomopsis cane leaf spot' 'phomopsis stem canker' 'phomopsis tip blight'\n",
      " 'phytophthora blight' 'phytophthora fruit rot' 'phytophthora root rot'\n",
      " 'pink disease corticium' 'pod blight diaporthe' 'pod stem blight'\n",
      " 'poria root disease poria hypolateritia' 'powdery mildew' 'purple blotch'\n",
      " 'ray blight didymella' 'red rot' 'red rust' 'rhabdocline needle cast'\n",
      " 'rhizoctonia limb rot' 'rhizome rot' 'rhizosphaera needle cast'\n",
      " 'ring spot mycosphaerella' 'ring spot virus' 'root knot nematode'\n",
      " 'root rot' 'root rot aphanomyces' 'root rot phymatotrichopsis'\n",
      " 'root rot phytophthora' 'root rot pythiumrhizoctonia' 'rust'\n",
      " 'rust gymnosporangium' 'rust late rust' 'rust melampsora'\n",
      " 'rust orangebrown' 'rust puccinia' 'rust tranzschelia' 'scab'\n",
      " 'scab cladosporium' 'scald rhynchosporium' 'sclerotinia rot white mold'\n",
      " 'sclerotium rot white mold' 'septoria brown spot' 'septoria leaf spot'\n",
      " 'septoria tritici blotch' 'sheath blight' 'sheath rot'\n",
      " 'shot hole stigmina' 'sigatoka leaf spot' 'smut' 'sooty blotch flyspeck'\n",
      " 'sooty mold' 'sour rot mixed pathogen' 'southern corn leaf blight'\n",
      " 'spider mite two spotted spider' 'spot anthracnose' 'spur blight'\n",
      " 'stalk rot' 'stem bleeding' 'stem rot' 'stem rot macrophomina'\n",
      " 'stemphylium leaf spot' 'stemphylium purple spot' 'sunblotch viroid'\n",
      " 'tar spot' 'target spot' 'tikka leaf spot' 'tip blight kabatina'\n",
      " 'tomato mosaic virus' 'tomato yellow leaf curl virus'\n",
      " 'tuber rot phytophthora' 'tulip break virus' 'verticillium wilt'\n",
      " 'volutella blight' 'walnut blight xanthomonas' 'white mold sclerotinia'\n",
      " 'white rot' 'white rot botryosphaeria' 'white rust' 'white rust albugo'\n",
      " 'white spot cercosporella' 'white tip phytophthora' 'wilt'\n",
      " 'wirestem rhizoctonia' 'witch broom disease' 'yellow vein mosaic virus']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa30b77c-2377-47e6-ae20-bee9117ea86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DistilBERT model loaded successfully!\n",
      "ðŸ§  Ready to fine-tune for 243 plant diseases.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "num_labels = len(label_encoder.classes_)  # number of unique diseases\n",
    "\n",
    "# Load pretrained DistilBERT model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "print(\"âœ… DistilBERT model loaded successfully!\")\n",
    "print(\"ðŸ§  Ready to fine-tune for\", num_labels, \"plant diseases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101f0fe6-7a94-4941-a221-062e1e55a61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data split done successfully!\n",
      "Train size: 2916 | Val size: 364 | Test size: 365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming your dataframe is still loaded as df\n",
    "# (with 'Cleaned_Symptoms' and 'Cleaned_Disease_Name' columns)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Cleaned_Disease_Name'])\n",
    "\n",
    "# Split 80/10/10\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['Cleaned_Symptoms'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(\"âœ… Data split done successfully!\")\n",
    "print(f\"Train size: {len(train_texts)} | Val size: {len(val_texts)} | Test size: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a22d002a-993f-4d07-886f-33b2fdb08d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize text data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "print(\"âœ… Tokenization complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb47da8c-a55d-4bf8-90cf-9e62b993ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Labels encoded successfully!\n",
      "Total unique diseases: 243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode disease labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_labels_enc = label_encoder.fit_transform(train_labels)\n",
    "val_labels_enc = label_encoder.transform(val_labels)\n",
    "test_labels_enc = label_encoder.transform(test_labels)\n",
    "\n",
    "print(\"âœ… Labels encoded successfully!\")\n",
    "print(f\"Total unique diseases: {len(label_encoder.classes_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dfbceb8-4f20-4656-ac54-f7131dcf5039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset objects created successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class PlantDiseaseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create PyTorch dataset objects\n",
    "train_dataset = PlantDiseaseDataset(train_encodings, train_labels_enc)\n",
    "val_dataset = PlantDiseaseDataset(val_encodings, val_labels_enc)\n",
    "test_dataset = PlantDiseaseDataset(test_encodings, test_labels_enc)\n",
    "\n",
    "print(\"âœ… Dataset objects created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc583d2c-01be-4cff-aa5e-3cef166a38a4",
   "metadata": {},
   "source": [
    "# Set Up Training Configuration and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7ef8b0d-5537-4537-ad9a-abf848608bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\AppData\\Local\\Temp\\ipykernel_15080\\473394398.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Trainer setup complete! Ready to start training ðŸš€\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# âœ… Training configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",                # folder to save model checkpoints\n",
    "    learning_rate=2e-5,                    # how fast the model learns\n",
    "    per_device_train_batch_size=8,         # batch size during training\n",
    "    per_device_eval_batch_size=8,          # batch size during evaluation\n",
    "    num_train_epochs=5,                    # try 5 for better learning\n",
    "    weight_decay=0.01,                     # helps reduce overfitting\n",
    "    logging_dir=\"./logs\",                  # folder for logs\n",
    "    save_total_limit=1                     # keep only the last checkpoint\n",
    ")\n",
    "\n",
    "# âœ… Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer setup complete! Ready to start training ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79f53b1-202f-4381-9a70-c82869be0bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1825' max='1825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1825/1825 46:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.957100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.854300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=1825, training_loss=3.6055207552975173, metrics={'train_runtime': 2796.3727, 'train_samples_per_second': 5.214, 'train_steps_per_second': 0.653, 'total_flos': 56826431069400.0, 'train_loss': 3.6055207552975173, 'epoch': 5.0})\n"
     ]
    }
   ],
   "source": [
    "train_output = trainer.train()\n",
    "print(train_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24d88d0f-ad93-4cdc-bc52-b165735b7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation Accuracy: 95.33%\n",
      "\n",
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.50      1.00      0.67         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      0.50      0.67         2\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         1\n",
      "          18       0.50      1.00      0.67         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       1.00      1.00      1.00         1\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         1\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       0.50      1.00      0.67         1\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         1\n",
      "          37       1.00      1.00      1.00         1\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         1\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         1\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         1\n",
      "          48       1.00      1.00      1.00         1\n",
      "          49       1.00      1.00      1.00         1\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      1.00      1.00         1\n",
      "          53       1.00      1.00      1.00         1\n",
      "          54       1.00      1.00      1.00         1\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       0.67      1.00      0.80         2\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         1\n",
      "          62       1.00      1.00      1.00         1\n",
      "          63       1.00      1.00      1.00         1\n",
      "          64       1.00      1.00      1.00         1\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         2\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         2\n",
      "          69       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         1\n",
      "          71       1.00      1.00      1.00         1\n",
      "          72       1.00      1.00      1.00         1\n",
      "          73       1.00      1.00      1.00         2\n",
      "          74       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         2\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.67      1.00      0.80         2\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         1\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       0.50      1.00      0.67         1\n",
      "          84       1.00      0.50      0.67         2\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       1.00      1.00      1.00         1\n",
      "          88       1.00      1.00      1.00         1\n",
      "          89       1.00      1.00      1.00         1\n",
      "          90       1.00      1.00      1.00         2\n",
      "          91       1.00      1.00      1.00         1\n",
      "          92       1.00      1.00      1.00         1\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       1.00      1.00      1.00         1\n",
      "          95       1.00      1.00      1.00         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         2\n",
      "          98       1.00      1.00      1.00         1\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       0.67      1.00      0.80         2\n",
      "         101       1.00      1.00      1.00         2\n",
      "         102       1.00      1.00      1.00         1\n",
      "         103       1.00      1.00      1.00         1\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       1.00      1.00      1.00         1\n",
      "         107       1.00      1.00      1.00         1\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       1.00      1.00      1.00         2\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       1.00      1.00      1.00         2\n",
      "         112       1.00      1.00      1.00         2\n",
      "         113       1.00      1.00      1.00         2\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         2\n",
      "         116       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       1.00      1.00      1.00         1\n",
      "         119       1.00      1.00      1.00         2\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       1.00      1.00      1.00         1\n",
      "         122       0.50      1.00      0.67         1\n",
      "         123       0.50      1.00      0.67         1\n",
      "         124       1.00      0.50      0.67         2\n",
      "         125       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         2\n",
      "         127       1.00      1.00      1.00         2\n",
      "         128       1.00      1.00      1.00         1\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       1.00      1.00      1.00         1\n",
      "         132       1.00      0.50      0.67         2\n",
      "         133       1.00      1.00      1.00         1\n",
      "         134       1.00      1.00      1.00         1\n",
      "         135       0.33      1.00      0.50         1\n",
      "         136       1.00      1.00      1.00         1\n",
      "         137       1.00      1.00      1.00         2\n",
      "         138       1.00      1.00      1.00         1\n",
      "         139       0.00      0.00      0.00         2\n",
      "         140       1.00      1.00      1.00         1\n",
      "         141       1.00      1.00      1.00         2\n",
      "         142       1.00      1.00      1.00         1\n",
      "         143       1.00      1.00      1.00         2\n",
      "         144       1.00      1.00      1.00         2\n",
      "         145       1.00      1.00      1.00         1\n",
      "         146       1.00      1.00      1.00         2\n",
      "         147       1.00      1.00      1.00         2\n",
      "         148       1.00      1.00      1.00         2\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       1.00      1.00      1.00         2\n",
      "         151       1.00      1.00      1.00         1\n",
      "         152       1.00      1.00      1.00         2\n",
      "         153       1.00      1.00      1.00         2\n",
      "         154       0.67      1.00      0.80         2\n",
      "         155       1.00      1.00      1.00         2\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       1.00      1.00      1.00         2\n",
      "         159       1.00      1.00      1.00         2\n",
      "         160       1.00      1.00      1.00         1\n",
      "         161       1.00      1.00      1.00         2\n",
      "         162       1.00      1.00      1.00         2\n",
      "         163       1.00      1.00      1.00         1\n",
      "         164       1.00      1.00      1.00         2\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       1.00      1.00      1.00         2\n",
      "         168       1.00      1.00      1.00         2\n",
      "         169       1.00      1.00      1.00         1\n",
      "         170       0.00      0.00      0.00         2\n",
      "         171       1.00      1.00      1.00         1\n",
      "         172       1.00      1.00      1.00         1\n",
      "         173       1.00      1.00      1.00         2\n",
      "         174       1.00      1.00      1.00         1\n",
      "         175       1.00      1.00      1.00         2\n",
      "         176       1.00      1.00      1.00         2\n",
      "         177       1.00      1.00      1.00         1\n",
      "         178       1.00      1.00      1.00         2\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       1.00      1.00      1.00         2\n",
      "         183       1.00      1.00      1.00         1\n",
      "         184       1.00      1.00      1.00         1\n",
      "         185       1.00      1.00      1.00         2\n",
      "         186       1.00      1.00      1.00         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       1.00      1.00      1.00         1\n",
      "         189       1.00      1.00      1.00         1\n",
      "         190       1.00      1.00      1.00         2\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       1.00      1.00      1.00         2\n",
      "         193       1.00      1.00      1.00         2\n",
      "         194       1.00      0.50      0.67         2\n",
      "         195       1.00      1.00      1.00         2\n",
      "         196       1.00      1.00      1.00         2\n",
      "         197       1.00      1.00      1.00         2\n",
      "         198       1.00      1.00      1.00         1\n",
      "         199       1.00      1.00      1.00         2\n",
      "         200       0.50      1.00      0.67         1\n",
      "         201       1.00      1.00      1.00         1\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       1.00      1.00      1.00         1\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       0.50      1.00      0.67         2\n",
      "         206       0.00      0.00      0.00         2\n",
      "         207       1.00      1.00      1.00         2\n",
      "         208       1.00      1.00      1.00         1\n",
      "         209       1.00      1.00      1.00         2\n",
      "         210       1.00      1.00      1.00         1\n",
      "         211       1.00      1.00      1.00         1\n",
      "         212       1.00      1.00      1.00         2\n",
      "         213       1.00      1.00      1.00         1\n",
      "         214       1.00      1.00      1.00         1\n",
      "         215       1.00      1.00      1.00         2\n",
      "         216       1.00      1.00      1.00         1\n",
      "         217       1.00      1.00      1.00         2\n",
      "         218       1.00      1.00      1.00         1\n",
      "         219       1.00      1.00      1.00         1\n",
      "         220       1.00      1.00      1.00         1\n",
      "         221       1.00      1.00      1.00         1\n",
      "         222       1.00      1.00      1.00         1\n",
      "         223       1.00      1.00      1.00         1\n",
      "         224       1.00      1.00      1.00         2\n",
      "         225       1.00      1.00      1.00         1\n",
      "         226       1.00      1.00      1.00         2\n",
      "         227       1.00      1.00      1.00         2\n",
      "         228       1.00      1.00      1.00         1\n",
      "         229       1.00      1.00      1.00         1\n",
      "         230       1.00      1.00      1.00         2\n",
      "         231       1.00      1.00      1.00         1\n",
      "         232       1.00      1.00      1.00         2\n",
      "         233       0.67      1.00      0.80         2\n",
      "         234       1.00      1.00      1.00         2\n",
      "         235       1.00      1.00      1.00         1\n",
      "         236       1.00      1.00      1.00         2\n",
      "         237       1.00      1.00      1.00         1\n",
      "         238       1.00      1.00      1.00         2\n",
      "         239       0.00      0.00      0.00         1\n",
      "         240       1.00      1.00      1.00         2\n",
      "         241       1.00      1.00      1.00         2\n",
      "         242       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.95       364\n",
      "   macro avg       0.94      0.96      0.94       364\n",
      "weighted avg       0.94      0.95      0.94       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get model predictions on validation data\n",
    "preds_logits = trainer.predict(val_dataset).predictions\n",
    "preds = preds_logits.argmax(axis=1)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(val_labels_enc, preds)\n",
    "print(f\"âœ… Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Detailed report\n",
    "print(\"\\nðŸ“Š Classification Report:\")\n",
    "print(classification_report(val_labels_enc, preds, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d09b0b75-fa48-469d-9a49-33c1fc1aca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Test Accuracy: 95.62%\n",
      "\n",
      "ðŸ“Š Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      0.50      0.67         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.40      1.00      0.57         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         1\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         1\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         1\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         1\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          41       1.00      1.00      1.00         1\n",
      "          42       0.50      1.00      0.67         1\n",
      "          43       1.00      1.00      1.00         2\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         1\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      1.00      1.00         1\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         1\n",
      "          56       1.00      1.00      1.00         1\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         2\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         1\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         2\n",
      "          64       1.00      1.00      1.00         2\n",
      "          65       1.00      1.00      1.00         1\n",
      "          66       0.33      1.00      0.50         1\n",
      "          67       1.00      1.00      1.00         1\n",
      "          68       1.00      1.00      1.00         1\n",
      "          69       1.00      1.00      1.00         1\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       0.67      1.00      0.80         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         2\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.50      1.00      0.67         1\n",
      "          79       1.00      1.00      1.00         1\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       0.67      1.00      0.80         2\n",
      "          84       1.00      1.00      1.00         1\n",
      "          85       1.00      1.00      1.00         1\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         1\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         2\n",
      "          95       1.00      1.00      1.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       1.00      1.00      1.00         2\n",
      "          99       1.00      1.00      1.00         2\n",
      "         100       1.00      1.00      1.00         1\n",
      "         101       1.00      1.00      1.00         1\n",
      "         102       1.00      1.00      1.00         2\n",
      "         103       1.00      1.00      1.00         2\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       1.00      0.50      0.67         2\n",
      "         106       1.00      1.00      1.00         2\n",
      "         107       1.00      1.00      1.00         2\n",
      "         108       1.00      1.00      1.00         1\n",
      "         109       1.00      1.00      1.00         1\n",
      "         110       1.00      1.00      1.00         2\n",
      "         111       1.00      1.00      1.00         1\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       1.00      1.00      1.00         1\n",
      "         114       1.00      1.00      1.00         1\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       1.00      1.00      1.00         2\n",
      "         119       1.00      1.00      1.00         1\n",
      "         120       1.00      1.00      1.00         1\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         2\n",
      "         123       1.00      1.00      1.00         2\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       1.00      1.00      1.00         1\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       1.00      1.00      1.00         1\n",
      "         128       0.67      1.00      0.80         2\n",
      "         129       1.00      1.00      1.00         2\n",
      "         130       0.00      0.00      0.00         2\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       1.00      1.00      1.00         1\n",
      "         133       1.00      1.00      1.00         2\n",
      "         134       1.00      1.00      1.00         2\n",
      "         135       0.50      1.00      0.67         2\n",
      "         136       1.00      1.00      1.00         2\n",
      "         137       1.00      1.00      1.00         1\n",
      "         138       1.00      1.00      1.00         2\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       1.00      1.00      1.00         2\n",
      "         141       1.00      1.00      1.00         1\n",
      "         142       1.00      1.00      1.00         2\n",
      "         143       1.00      1.00      1.00         1\n",
      "         144       1.00      1.00      1.00         1\n",
      "         145       1.00      1.00      1.00         2\n",
      "         146       1.00      1.00      1.00         1\n",
      "         147       1.00      1.00      1.00         1\n",
      "         148       1.00      1.00      1.00         1\n",
      "         149       1.00      1.00      1.00         2\n",
      "         150       1.00      1.00      1.00         1\n",
      "         151       1.00      1.00      1.00         2\n",
      "         152       1.00      1.00      1.00         1\n",
      "         153       1.00      1.00      1.00         1\n",
      "         154       1.00      1.00      1.00         1\n",
      "         155       0.50      1.00      0.67         1\n",
      "         156       0.67      1.00      0.80         2\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       1.00      1.00      1.00         1\n",
      "         159       1.00      1.00      1.00         1\n",
      "         160       1.00      1.00      1.00         2\n",
      "         161       1.00      1.00      1.00         1\n",
      "         162       1.00      1.00      1.00         1\n",
      "         163       1.00      1.00      1.00         2\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       1.00      1.00      1.00         2\n",
      "         166       1.00      1.00      1.00         2\n",
      "         167       1.00      1.00      1.00         1\n",
      "         168       1.00      1.00      1.00         1\n",
      "         169       1.00      1.00      1.00         2\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       1.00      1.00      1.00         2\n",
      "         172       1.00      1.00      1.00         2\n",
      "         173       1.00      1.00      1.00         1\n",
      "         174       1.00      1.00      1.00         2\n",
      "         175       1.00      1.00      1.00         1\n",
      "         176       1.00      1.00      1.00         1\n",
      "         177       1.00      0.50      0.67         2\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         2\n",
      "         180       1.00      1.00      1.00         1\n",
      "         181       1.00      1.00      1.00         2\n",
      "         182       1.00      1.00      1.00         1\n",
      "         183       1.00      1.00      1.00         2\n",
      "         184       1.00      1.00      1.00         2\n",
      "         185       1.00      1.00      1.00         1\n",
      "         186       1.00      1.00      1.00         2\n",
      "         187       0.00      0.00      0.00         2\n",
      "         188       1.00      1.00      1.00         2\n",
      "         189       1.00      1.00      1.00         2\n",
      "         190       1.00      1.00      1.00         1\n",
      "         191       1.00      1.00      1.00         2\n",
      "         192       1.00      1.00      1.00         1\n",
      "         193       1.00      1.00      1.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       1.00      1.00      1.00         1\n",
      "         196       1.00      1.00      1.00         1\n",
      "         197       1.00      1.00      1.00         1\n",
      "         198       1.00      1.00      1.00         2\n",
      "         199       1.00      1.00      1.00         1\n",
      "         200       0.67      1.00      0.80         2\n",
      "         201       1.00      1.00      1.00         2\n",
      "         202       1.00      1.00      1.00         2\n",
      "         203       1.00      1.00      1.00         2\n",
      "         204       1.00      1.00      1.00         2\n",
      "         205       0.50      1.00      0.67         1\n",
      "         206       1.00      1.00      1.00         1\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       1.00      1.00      1.00         2\n",
      "         209       1.00      1.00      1.00         1\n",
      "         210       1.00      1.00      1.00         2\n",
      "         211       1.00      1.00      1.00         2\n",
      "         212       1.00      1.00      1.00         1\n",
      "         213       1.00      1.00      1.00         2\n",
      "         214       1.00      1.00      1.00         2\n",
      "         215       1.00      1.00      1.00         1\n",
      "         216       1.00      1.00      1.00         2\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       1.00      1.00      1.00         2\n",
      "         219       1.00      1.00      1.00         2\n",
      "         220       1.00      1.00      1.00         2\n",
      "         221       1.00      1.00      1.00         2\n",
      "         222       1.00      1.00      1.00         2\n",
      "         223       1.00      1.00      1.00         2\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       1.00      1.00      1.00         2\n",
      "         226       1.00      1.00      1.00         1\n",
      "         227       1.00      1.00      1.00         1\n",
      "         228       1.00      1.00      1.00         2\n",
      "         229       1.00      0.50      0.67         2\n",
      "         230       1.00      1.00      1.00         1\n",
      "         231       1.00      1.00      1.00         2\n",
      "         232       1.00      1.00      1.00         1\n",
      "         233       1.00      1.00      1.00         1\n",
      "         234       1.00      1.00      1.00         1\n",
      "         235       1.00      1.00      1.00         2\n",
      "         236       1.00      1.00      1.00         1\n",
      "         237       1.00      1.00      1.00         2\n",
      "         238       1.00      1.00      1.00         1\n",
      "         239       1.00      1.00      1.00         2\n",
      "         240       1.00      1.00      1.00         1\n",
      "         241       1.00      1.00      1.00         1\n",
      "         242       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       365\n",
      "   macro avg       0.94      0.95      0.94       365\n",
      "weighted avg       0.94      0.96      0.95       365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\akhil\\OneDrive\\Desktop\\PlantDocBot\\venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on test set\n",
    "test_preds_logits = trainer.predict(test_dataset).predictions\n",
    "test_preds = test_preds_logits.argmax(axis=1)\n",
    "\n",
    "# Compute test accuracy\n",
    "test_accuracy = accuracy_score(test_labels_enc, test_preds)\n",
    "print(f\"ðŸ§ª Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Detailed test report\n",
    "print(\"\\nðŸ“Š Test Classification Report:\")\n",
    "print(classification_report(test_labels_enc, test_preds, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c3531c-ead1-4f09-994c-edeb3730d12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model, tokenizer, and label encoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# âœ… Create a folder to store model files\n",
    "model.save_pretrained(\"../models/final_distilbert_model\")\n",
    "tokenizer.save_pretrained(\"../models/final_distilbert_model\")\n",
    "\n",
    "# âœ… Also save your label encoder\n",
    "import joblib\n",
    "joblib.dump(label_encoder, \"../models/label_encoder.pkl\")\n",
    "\n",
    "print(\"âœ… Model, tokenizer, and label encoder saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "300f8bc1-4261-4a9e-a673-e5aca57be188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model, tokenizer, and label encoder loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import joblib\n",
    "\n",
    "# âœ… Load everything\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"../models/final_distilbert_model\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"../models/final_distilbert_model\")\n",
    "label_encoder = joblib.load(\"../models/label_encoder.pkl\")\n",
    "\n",
    "print(\"âœ… Model, tokenizer, and label encoder loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7559018a-b6a3-4fbd-b125-aea584095652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "label_encoder = joblib.load(\"../models/label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d95ac747-a05e-4591-9202-9e1c7bcb39ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'final_distilbert_model', 'final_plant_disease_NLP_model', 'label_encoder.pkl', 'logs', 'logs_top20', 'logs_top20_v2', 'mobilenetv2_final.h5', 'mobilenetv2_finetune.h5', 'mobilenetv2_stage1.h5', 'PlantDocBot_NLP_Model', 'PlantDocBot_Tokenizer', 'PlantDoc_TextModel_v2', 'PlantDoc_Text_Model', 'results', 'results_top20', 'results_top20_v2']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"../models\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3629e7e3-922a-411c-ac12-029815b90cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label encoder loaded successfully!\n",
      "Number of classes: 243\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "label_encoder = joblib.load(\"../models/label_encoder.pkl\")\n",
    "print(\"âœ… Label encoder loaded successfully!\")\n",
    "print(\"Number of classes:\", len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "831053ce-db77-4913-88fb-0d576cb1f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Correct label encoder rebuilt and saved!\n",
      "Number of disease classes: 243\n",
      "Sample class names: ['aerial blight phytophthora' 'algal leaf spot green scurf'\n",
      " 'alternaria leaf blight' 'alternaria leaf spot'\n",
      " 'angular leaf spot bacterial' 'anthracnose' 'anthracnose colletotrichum'\n",
      " 'apple scab' 'ascochyta blight' 'bacterial blast pseudomonas'\n",
      " 'bacterial blight' 'bacterial blight angular leaf spot'\n",
      " 'bacterial blight xanthomonas' 'bacterial canker' 'bacterial leaf blight']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# recreate label encoder from the training dataframe\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df[\"Cleaned_Disease_Name\"])\n",
    "\n",
    "# save it so we can reuse later\n",
    "joblib.dump(label_encoder, \"../models/label_encoder.pkl\")\n",
    "\n",
    "print(\"âœ… Correct label encoder rebuilt and saved!\")\n",
    "print(\"Number of disease classes:\", len(label_encoder.classes_))\n",
    "print(\"Sample class names:\", label_encoder.classes_[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5975cd9-7380-4e37-b690-383ff91d447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ©º Symptom: yellow circular spots on tomato leaves\n",
      "ðŸŒ¿ Predicted Disease: leaf spot common leaf spot\n",
      "ðŸ“Š Confidence: 2.28%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import joblib\n",
    "\n",
    "# Load encoder and test sample\n",
    "label_encoder = joblib.load(\"../models/label_encoder.pkl\")\n",
    "\n",
    "text = \"yellow circular spots on tomato leaves\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "confidence = torch.max(probs).item() * 100\n",
    "pred_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "pred_disease = label_encoder.inverse_transform([pred_label])[0]\n",
    "\n",
    "print(f\"ðŸ©º Symptom: {text}\")\n",
    "print(f\"ðŸŒ¿ Predicted Disease: {pred_disease}\")\n",
    "print(f\"ðŸ“Š Confidence: {confidence:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2f31145-b72c-44d9-a555-56115818ef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Fitted temperature: 0.1000, Mean confidence: 98.53%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Get model predictions (logits) on validation set\n",
    "val_logits = trainer.predict(val_dataset).predictions\n",
    "val_probs = torch.nn.functional.softmax(torch.tensor(val_logits), dim=1).numpy()\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "val_true = np.array(val_labels_enc)\n",
    "\n",
    "# Temperature scaling\n",
    "def temperature_scale(logits, temp):\n",
    "    logits = torch.tensor(logits)\n",
    "    return torch.nn.functional.softmax(logits / temp, dim=1).numpy()\n",
    "\n",
    "temps = np.linspace(0.1, 2.0, 20)\n",
    "best_temp = 1.0\n",
    "best_conf = 0\n",
    "\n",
    "for t in temps:\n",
    "    scaled_probs = temperature_scale(val_logits, t)\n",
    "    mean_conf = np.mean(np.max(scaled_probs, axis=1))\n",
    "    if mean_conf > best_conf:\n",
    "        best_conf = mean_conf\n",
    "        best_temp = t\n",
    "\n",
    "print(f\"ðŸ”¥ Fitted temperature: {best_temp:.4f}, Mean confidence: {best_conf*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8230556d-e7b1-46b3-b4c3-8a8e7dabb592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ©º Symptom: yellow circular spots on tomato leaves\n",
      "ðŸŒ¿ Predicted Disease: leaf spot common leaf spot\n",
      "ðŸ“Š Confidence: 64.19%\n",
      "\n",
      "ðŸ©º Symptom: white powdery coating on leaves\n",
      "ðŸŒ¿ Predicted Disease: ganoderma butt rot\n",
      "ðŸ“Š Confidence: 70.10%\n",
      "\n",
      "ðŸ©º Symptom: brown patches with dark edges on fruits\n",
      "ðŸŒ¿ Predicted Disease: fruit spot cercospora\n",
      "ðŸ“Š Confidence: 61.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "temperature = 0.1  # from calibration step\n",
    "\n",
    "texts = [\n",
    "    \"yellow circular spots on tomato leaves\",\n",
    "    \"white powdery coating on leaves\",\n",
    "    \"brown patches with dark edges on fruits\"\n",
    "]\n",
    "\n",
    "for t in texts:\n",
    "    inputs = tokenizer(t, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits / temperature  # ðŸ”¥ calibrated logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    confidence = torch.max(probs).item() * 100\n",
    "    pred_label = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    pred_disease = label_encoder.inverse_transform([pred_label])[0]\n",
    "\n",
    "    print(f\"ðŸ©º Symptom: {t}\")\n",
    "    print(f\"ðŸŒ¿ Predicted Disease: {pred_disease}\")\n",
    "    print(f\"ðŸ“Š Confidence: {confidence:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352df60a-bbf9-4367-9f01-06238d62adf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
